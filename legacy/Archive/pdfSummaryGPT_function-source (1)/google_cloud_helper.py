import os
import json
from google.cloud import storage, vision

def upload_to_gcs(bucket_name, source_file_name, destination_file_name):
    """Uploads a file to Google Cloud Storage."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_file_name)

    blob.upload_from_filename(source_file_name)
    print(f"File {source_file_name} uploaded to {destination_file_name}.")

def extract_text_with_vision_api(gcs_uri, output_gcs_uri_prefix):
    """
    Extract text from a PDF file stored in Google Cloud Storage using Vision API.

    :param gcs_uri: The URI of the PDF in Google Cloud Storage (e.g., "gs://bucket-name/file.pdf").
    :param output_gcs_uri_prefix: The URI prefix where the output JSON will be stored in GCS.
    """
    client = vision.ImageAnnotatorClient()

    # Configure the input GCS location
    gcs_source = vision.GcsSource(uri=gcs_uri)
    input_config = vision.InputConfig(
        gcs_source=gcs_source, mime_type="application/pdf"
    )

    # Configure the output GCS location
    gcs_destination = vision.GcsDestination(uri=output_gcs_uri_prefix)
    output_config = vision.OutputConfig(
        gcs_destination=gcs_destination, batch_size=1
    )

    # Create a request for async document text detection
    async_request = vision.AsyncAnnotateFileRequest(
        features=[vision.Feature(type=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)],
        input_config=input_config,
        output_config=output_config,
    )

    # Make the request
    operation = client.async_batch_annotate_files(requests=[async_request])
    print("Processing file with Vision API...")
    operation.result(timeout=300)

    print(f"Text extraction complete. Output saved to {output_gcs_uri_prefix}")

def download_all_vision_outputs(bucket_name, output_prefix, destination_folder="output_files"):
    """Downloads all output JSON files generated by Vision API."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)

    # Create a local folder to save downloaded JSON files
    if not os.path.exists(destination_folder):
        os.makedirs(destination_folder)

    # List all blobs in the bucket with the output prefix
    blobs = bucket.list_blobs(prefix=output_prefix)
    local_files = []

    for blob in blobs:
        local_file_path = os.path.join(destination_folder, os.path.basename(blob.name))
        blob.download_to_filename(local_file_path)
        local_files.append(local_file_path)
        print(f"Downloaded {blob.name} to {local_file_path}")

    return local_files

def extract_text_from_multiple_vision_outputs(output_files):
    """Aggregates text from multiple JSON files generated by Vision API."""
    aggregated_text = ""

    for output_file in output_files:
        with open(output_file, "r", encoding="utf-8") as f:
            response = json.load(f)
            for response_page in response.get("responses", []):
                if "fullTextAnnotation" in response_page:
                    aggregated_text += response_page["fullTextAnnotation"]["text"]

    return aggregated_text

def extract_text_from_pdf_with_vision(pdf_path, bucket_name):
    """
    Full pipeline to upload a PDF to GCS, process with Vision API, and retrieve aggregated text.
    """
    try:
        # Define folders and file names
        sanitized_file_name = os.path.basename(pdf_path).replace(" ", "_")
        input_folder = "pitch-decks"
        output_folder = "vision-output"

        # Upload the PDF to GCS
        gcs_uri = f"gs://{bucket_name}/{input_folder}/{sanitized_file_name}"
        upload_to_gcs(bucket_name, pdf_path, f"{input_folder}/{sanitized_file_name}")

        # Construct the output GCS URI prefix
        output_gcs_uri_prefix = f"gs://{bucket_name}/{output_folder}/{sanitized_file_name.replace('.pdf', '_output.json')}"

        # Extract text using Vision API
        print(f"Starting Vision API extraction. Input URI: {gcs_uri}, Output URI Prefix: {output_gcs_uri_prefix}")
        extract_text_with_vision_api(gcs_uri, output_gcs_uri_prefix)

        # Download all output files generated by Vision API
        output_files = download_all_vision_outputs(bucket_name, f"{output_folder}/{sanitized_file_name.replace('.pdf', '_output.json')}")

        # Extract and aggregate text from all JSON files
        aggregated_text = extract_text_from_multiple_vision_outputs(output_files)

        return aggregated_text

    except Exception as e:
        print(f"Error during text extraction with Vision API: {e}")
        raise
